### start initialization
library(Seurat)
library(future)
library(patchwork)
library(ggplot2)
library(chron)
library(tidyr)
library(dplyr)
## TODO build in SCT based DEG: https://satijalab.org/seurat/articles/sctransform_v2_vignette.html
# SCT DEG: we make use of 'corrected counts' that are stored in the data slot of the the SCT assay
# SCTransform combines NormalizeData (better normalization), ScaleData and FindVariableFeatures
## v2 upgrades: https://satijalab.org/seurat/articles/sctransform_v2_vignette.html#perform-integration-using-pearson-residuals-1
# normally SCT used for dadta transformations that are then used for: PCA, clustering, UMAP
# before, RNA assay was used for DE, as SCT Pearson residuals could not resolve batch effects in comparison
## now: this is the optimized way of doing DE analysis
# can use top VariableFeatureGenes for marker identifictation: https://www.biostars.org/p/406388/
# RNA assay: counts@rawcounts / TPMs, data@normalized data, scale.data@scaled data
# SCT assay: counts@corrected counts, data@log1p(counts), scale.data@pearson residuals
# TODO commented out FGSEA analysis for now, focus on DEGA
# TODO put in it's own file and source from here or pipeline
## TODO tryout sourcing in test file by setting working directory and seeing how sourcing behaves with a mock function
# TODO add rm cleanup environment to end of function
# TODO check maximum Windows file length and output pathway (partial) name instead of order for enrichment plot
# FGSEA package: vignette: http://127.0.0.1:31440/library/fgsea/doc/fgsea-tutorial.html
FGSEA_analysis <- function(markers, working_directory, marker_type, cluster) {
library(biomaRt)
library(fgsea)
library(data.table)
library(ggplot2)
message("loading FGSEA analysis function")
dir.create(paste0(work_dir, "../GSE_analysis/", marker_type, "/cluster ", cluster, "/"), recursive = T)
## fix infinite values later by applying -log10 function
markers$p_val[markers$p_val == 0] <- min(markers$p_val[markers$p_val != 0])
## calculate metric by FoldChangeSign and -LogPvalue
markers$fcsign <- sign(markers$avg_log2FC)
markers$logPval <- -log10(markers$p_val)
## create ranked vector
fgsea_ranks <- markers$logPval/markers$fcsign
## get Entrez IDs by HGNC symbol to match gene names and provide a translation map
hsmart <- useMart(dataset = "hsapiens_gene_ensembl", biomart = "ensembl")
mapping <- getBM(
attributes = c('entrezgene_id', 'hgnc_symbol'),
filters = 'hgnc_symbol',
values = rownames(markers),
mart = hsmart
)
names(fgsea_ranks) <- match(rownames(markers), mapping$hgnc_symbol)
## get Reactome pathways by Entrez IDs
pathways <- reactomePathways(names(fgsea_ranks))
fgsea_results <- fgsea(pathways = pathways,
stats    = fgsea_ranks,
eps      = 0.0,
minSize  = 15,
maxSize  = 500)
topPathwaysUp <- fgsea_results[ES > 0][head(order(pval), n=10), pathway]
topPathwaysDown <- fgsea_results[ES < 0][head(order(pval), n=10), pathway]
topPathways <- c(topPathwaysUp, rev(topPathwaysDown))
png(filename=paste0(working_directory, "../GSE_analysis/", marker_type, "/cluster ", cluster, "/overview_table.png"), width = 1600)
plotGseaTable(pathways[topPathways], fgsea_ranks, fgsea_results,
gseaParam=0.5)
dev.off()
## can try to collapse pathways if there are many seemlingly alike in the plot above
collapsedPathways <- collapsePathways(fgsea_results[order(pval)][padj < 0.01],
pathways, fgsea_ranks)
mainPathways <- fgsea_results[pathway %in% collapsedPathways$mainPathways][
order(-NES), pathway]
## check if mainPathways is empty (likely collapsedPathways is empty too)
if (length(mainPathways) > 0) {
png(filename=paste0(working_directory, "../GSE_analysis/", marker_type, "/cluster ", cluster, "/collapsed_table.png"), width = 1600)
p <- plotGseaTable(pathways[mainPathways], fgsea_ranks, fgsea_results,
gseaParam = 0.5)
dev.off()
}
fwrite(fgsea_results, file=paste0(working_directory, "../GSE_analysis/", marker_type, "/cluster ", cluster, "/overview.xls"), sep="\t", sep2=c("", ",", ""))
for (i in seq_along(topPathways)) {
# png(filename=paste0(working_directory, "GSEA/cluster_", cluster, "/enriched_", i, ".png"), width = 1600)
p <- plotEnrichment(pathways[[topPathways[i]]],
fgsea_ranks) + labs(title=topPathways[[i]])
ggsave(file = paste0(working_directory, "../GSE_analysis/", marker_type, "/cluster ", cluster, "/enriched_", i, ".png"), width = 30, height = 20, units = "cm")
}
}
## OVERRIDE SEURAT DE FUNCTIONS WITH ADDITIONAL FUNCTIONALITY
# fixInNamespace(FindMarkers.Assay, pos = "package:Seurat") # use this to copy source code
# trace(Seurat:::FindMarkers.Assay, edit = T)
## but then need: untrace(Seurat:::FindMarkers.Assay) # to undo edits by tracing, will also be undone on reloading R
### all these functions call edit() under the hood
FoldChange.default.adjusted <- function (object, cells.1, cells.2, mean.fxn, fc.name, mean.fxn.adj = mean.fxn.adj, features = NULL, ...)
{
features <- features %||% rownames(x = object)
thresh.min <- 0
pct.1 <- round(x = rowSums(x = object[features, cells.1,
drop = FALSE] > thresh.min)/length(x = cells.1), digits = 3)
pct.2 <- round(x = rowSums(x = object[features, cells.2,
drop = FALSE] > thresh.min)/length(x = cells.2), digits = 3)
data.1 <- mean.fxn(object[features, cells.1, drop = FALSE])
data.2 <- mean.fxn(object[features, cells.2, drop = FALSE])
fc <- (data.1 - data.2)
### MY INJECTED CUSTOM CODE
n_nonzero.1 <- rowSums(x = object[features, cells.1, drop = FALSE] > 0)
n_nonzero.2 <- rowSums(x = object[features, cells.2, drop = FALSE] > 0)
object[object==0] <- NA
# Seurat code
mean.fxn <- mean.fxn %||% switch(
EXPR = slot,
'data' = function(x) {
return(log(x = rowMeans(x = expm1(x = x)) + pseudocount.use, base = base))
},
'scale.data' = rowMeans,
function(x) {
return(log(x = rowMeans(x = x) + pseudocount.use, base = base))
}
)
## Custom code for temporary custom mean.fxn.adj to calculate proper rowMeans for non-zero expressing cells
# added: na.rm = TRUE, such that 0's not taken into account for row means
# pseudocount.use = 1, base = 2, hardcoded because of namespace issues
mean.fxn.adj <- function (x)
{
return(log(x = mean(x = expm1(x = x), na.rm = T) + 1,
base = 2))
}
mean.fxn.adj <- mean.fxn.adj %||% switch(
EXPR = slot,
'data' = function(x) {
return(log(x = mean(x = expm1(x = x), na.rm = T) + 1, base = 2))
},
'scale.data' = rowMeans,
function(x) {
return(log(x = mean(x = x, na.rm = T) + 1, base = 2))
}
)
nonzero_data.1 <- apply(object[features, cells.1, drop = FALSE], 1, mean.fxn.adj)
nonzero_data.2 <- apply(object[features, cells.2, drop = FALSE], 1, mean.fxn.adj)
nonzero_fc <- (nonzero_data.1 - nonzero_data.2)
nonzero_fc[is.na(nonzero_fc)] <- 0
# ADJUSTED by adding: nonzero_fc, n_nonzero.1, n_nonzero.2
fc.results <- as.data.frame(x = cbind(fc, pct.1, pct.2, data.1, data.2, nonzero_fc, n_nonzero.1, n_nonzero.2,
nonzero_data.1, nonzero_data.2))
# ADJUSTED by adding: "nz_log_fc", "n_nz.1", "n_nz.2"
colnames(fc.results) <- c(fc.name, "pct.1", "pct.2", "meanExpr.1", "meanExpr.2",
paste0("nz_", fc.name), "nz_n.1", "nz_n.2", "nz_meanExpr.1", "nz_meanExpr.2")
return(fc.results)
}
# WORKS, but, if it fails after all continue searching
## https://stackoverflow.com/questions/8204008/redirect-intercept-function-calls-within-a-package-function
# namespace of customFunction is R_globalenv, where it is defined, bur should be Seurat as that is ns of my targeted function
environment(FoldChange.default.adjusted) <- asNamespace("Seurat")
# then with assignInNameSpace I can basically inject my code their copied function and then substitute it back in their environment
assignInNamespace("FoldChange.default", FoldChange.default.adjusted, ns = "Seurat")
WilcoxDETest.adjusted <- function (data.use, cells.1, cells.2, verbose = TRUE, ...)
{
# save data.use for non-zero calculation in case it is filtered too much beforehand
data.use.orig <- data.use
# use only data needed for group comparison
data.use <- data.use[, c(cells.1, cells.2), drop = FALSE]
# create sequential index of group 1 cells
j <- seq_len(length.out = length(x = cells.1))
# use ProgressBarSApply or FutureSApply (sequential/parallel processing)
my.sapply <- ifelse(test = verbose && future::nbrOfWorkers() ==
1, yes = pbsapply, no = future_sapply)
# check if not overflowing (data is NaN)
overflow.check <- ifelse(test = is.na(x = suppressWarnings(length(x = data.use[1,
]) * length(x = data.use[1, ]))), yes = FALSE, no = TRUE)
# check if limma package available in R session
limma.check <- PackageCheck("limma", error = FALSE)
# if data not overflowing and limma package available in R session
if (limma.check[1] && overflow.check) {
# calculate p-value with defined sapply function
p_val <- my.sapply(X = 1:nrow(x = data.use), FUN = function(x) {
return(min(2 * min(limma::rankSumTestWithCorrelation(index = j,
statistics = data.use[x, ])), 1))
})
}
else {
if (getOption("Seurat.limma.wilcox.msg", TRUE) && overflow.check) {
message("For a more efficient implementation of the Wilcoxon Rank Sum Test,",
"\n(default method for FindMarkers) please install the limma package",
"\n--------------------------------------------",
"\ninstall.packages('BiocManager')", "\nBiocManager::install('limma')",
"\n--------------------------------------------",
"\nAfter installation of limma, Seurat will automatically use the more ",
"\nefficient implementation (no further action necessary).",
"\nThis message will be shown once per session")
options(Seurat.limma.wilcox.msg = FALSE)
}
group.info <- data.frame(row.names = c(cells.1, cells.2))
group.info[cells.1, "group"] <- "Group1"
group.info[cells.2, "group"] <- "Group2"
group.info[, "group"] <- factor(x = group.info[, "group"])
data.use <- data.use[, rownames(x = group.info), drop = FALSE]
p_val <- my.sapply(X = 1:nrow(x = data.use), FUN = function(x) {
return(wilcox.test(data.use[x, ] ~ group.info[,
"group"], ...)$p.value)
})
}
### CUSTOM CODE for calculating p-value for non-zero expression cells
# use only non-zero expression data needed for group comparison
data.use <- data.use.orig[, c(cells.1, cells.2), drop = FALSE]
if (limma.check[1] && overflow.check) {
# calculate p-value with defined sapply function
nz_p_val <- my.sapply(X = 1:nrow(x = data.use), FUN = function(x) {
return(min(2 * min(limma::rankSumTestWithCorrelation(index = seq_len(sum(names(data.use[x,][data.use[x,] > 0]) %in% cells.1)),
statistics = data.use[x,][data.use[x,] > 0]
)), 1))
})
}
else {
data.use <- data.use[, rownames(x = group.info), drop = FALSE]
nz_p_val <- my.sapply(X = 1:nrow(x = data.use), FUN = function(x) {
return(wilcox.test(data.use[x, ] ~ group.info[,
"group"], ...)$p.value)
})
}
return(data.frame(p_val, nz_p_val, row.names = rownames(x = data.use)))
}
# change namespace of adjusted function to target function
environment(WilcoxDETest.adjusted) <- asNamespace("Seurat")
# now overrice target function within that namespace with my custom function
assignInNamespace("WilcoxDETest", WilcoxDETest.adjusted, ns = "Seurat")
FindMarkers.default.adjusted <- function(
object,
slot = "data",
counts = numeric(),
cells.1 = NULL,
cells.2 = NULL,
features = NULL,
logfc.threshold = 0.25,
test.use = 'wilcox',
min.pct = 0.1,
min.diff.pct = -Inf,
verbose = TRUE,
only.pos = FALSE,
max.cells.per.ident = Inf,
random.seed = 1,
latent.vars = NULL,
min.cells.feature = 3,
min.cells.group = 3,
pseudocount.use = 1,
fc.results = NULL,
densify = FALSE,
...
) {
ValidateCellGroups(
object = object,
cells.1 = cells.1,
cells.2 = cells.2,
min.cells.group = min.cells.group
)
features <- features %||% rownames(x = object)
# reset parameters so no feature filtering is performed
if (test.use %in% DEmethods_noprefilter()) {
features <- rownames(x = object)
min.diff.pct <- -Inf
logfc.threshold <- 0
}
data <- switch(
EXPR = slot,
'scale.data' = counts,
object
)
# feature selection (based on percentages)
alpha.min <- pmax(fc.results$pct.1, fc.results$pct.2)
names(x = alpha.min) <- rownames(x = fc.results)
features <- names(x = which(x = alpha.min >= min.pct))
if (length(x = features) == 0) {
warning("No features pass min.pct threshold; returning empty data.frame")
return(fc.results[features, ])
}
alpha.diff <- alpha.min - pmin(fc.results$pct.1, fc.results$pct.2)
features <- names(
x = which(x = alpha.min >= min.pct & alpha.diff >= min.diff.pct)
)
if (length(x = features) == 0) {
warning("No features pass min.diff.pct threshold; returning empty data.frame")
return(fc.results[features, ])
}
# feature selection (based on logFC)
if (slot != "scale.data") {
total.diff <- fc.results[, 1] #first column is logFC
names(total.diff) <- rownames(fc.results)
features.diff <- if (only.pos) {
names(x = which(x = total.diff >= logfc.threshold))
} else {
names(x = which(x = abs(x = total.diff) >= logfc.threshold))
}
features <- intersect(x = features, y = features.diff)
if (length(x = features) == 0) {
warning("No features pass logfc.threshold threshold; returning empty data.frame")
return(fc.results[features, ])
}
}
# subsample cell groups if they are too large
if (max.cells.per.ident < Inf) {
set.seed(seed = random.seed)
if (length(x = cells.1) > max.cells.per.ident) {
cells.1 <- sample(x = cells.1, size = max.cells.per.ident)
}
if (length(x = cells.2) > max.cells.per.ident) {
cells.2 <- sample(x = cells.2, size = max.cells.per.ident)
}
if (!is.null(x = latent.vars)) {
latent.vars <- latent.vars[c(cells.1, cells.2), , drop = FALSE]
}
}
de.results <- PerformDE(
object = object,
cells.1 = cells.1,
cells.2 = cells.2,
features = features,
test.use = test.use,
verbose = verbose,
min.cells.feature = min.cells.feature,
latent.vars = latent.vars,
densify = densify,
...
)
de.results <- cbind(de.results, fc.results[rownames(x = de.results), , drop = FALSE])
if (only.pos) {
de.results <- de.results[de.results[, 2] > 0, , drop = FALSE]
}
if (test.use %in% DEmethods_nocorrect()) {
de.results <- de.results[order(-de.results$power, -de.results[, 1]), ]
} else {
de.results <- de.results[order(de.results$p_val, -de.results[, 1]), ]
de.results$p_val_adj = p.adjust(
p = de.results$p_val,
method = "bonferroni",
n = nrow(x = object)
)
# MY CUSTOM CODE: also perform Bonferroni correction for non-zero expression DE data
de.results$nz_p_val_adj = p.adjust(
p = de.results$nz_p_val,
method = "bonferroni",
n = nrow(x = object)
)
# sort table column names
de.results <- de.results[,c(1, 13, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2, 14)]
}
return(de.results)
}
# change namespace of adjusted function to target function
environment(FindMarkers.default.adjusted) <- asNamespace("Seurat")
# now overrice target function within that namespace with my custom function
assignInNamespace("FindMarkers.default", FindMarkers.default.adjusted, ns = "Seurat")
message("loaded custom DE functions that overwrite Seurat namespace")
### END DE INITIALIZATION ###
### USER PARAMETERS
# read an integrated saved RDS file
sample_name <- "BL_N + BL_C"
integrated <- readRDS("F:/Maurits/EMC_SKlab_scRNA data/results/Pipe_SCTv2_corrected_13-06/integrated - new selection/BL_N + BL_C/BL_N + BL_C.rds")
# set default assay to SCT
DefaultAssay(integrated) <- "SCT"
integrated$orig.ident
df(integrated$orig.ident, integrated$seurat_clusters)
as.data.frame(integrated$orig.ident, integrated$seurat_clusters)
integrated$seurat_clusters
data.frame(integrated$orig.ident, integrated$seurat_clusters)
test <- data.frame(integrated$orig.ident, integrated$seurat_clusters)
test[test$integrated.orig.ident == 6]
test$integrated.orig.ident
test[test$seurat_clusters == 6]
head(test)
test[test$integrated.seurat_clusters == 6]
test$integrated.seurat_clusters == 6
table(test$integrated.seurat_clusters == 6)
test
test[test$integrated.seurat_clusters == 6]
test[test$integrated.seurat_clusters == 6,]
test[test$integrated.seurat_clusters == 6 && test$integrated.orig.ident == "BL_N",]
test[test$integrated.seurat_clusters == 1 && test$integrated.orig.ident == "BL_N",]
test[test$integrated.orig.ident == "BL_N",]
test[test$integrated.seurat_clusters == 11 && test$integrated.orig.ident == "BL_N",]
test[test$integrated.seurat_clusters == 11 && test$integrated.orig.ident == "BL_N",]
test[test$integrated.seurat_clusters == 11]
test[test$integrated.seurat_clusters == 11,]
test[test$integrated.seurat_clusters == 6,]
table(test[test$integrated.seurat_clusters == 6,]$integrated.orig.ident)
table(test[test$integrated.seurat_clusters == 6,]$integrated.orig.ident) < 3
any(c(TRUE, FALSE))
all(c(TRUE, FALSE))
all(c(FALSE, FALSE))
any(c(FALSE, FALSE))
table(test[test$integrated.seurat_clusters == 6,]$integrated.orig.ident) < 3
if (any(table(test[test$integrated.seurat_clusters == 6,]$integrated.orig.ident) < 3)) {
print(123)
}
if (any(table(test[test$integrated.seurat_clusters == 5,]$integrated.orig.ident) < 3)) {
print(123)
}
cm_val1 <- 4
cm_val2 <- 4
cm_val3 <- 4
cm_val4 <- 4
c(cm_val1, cm_val2, cm_val3, cm_val4)
c(cm_val1, cm_val2, cm_val3, cm_val4) < 3
any(c(cm_val1, cm_val2, cm_val3, cm_val4) < 3)
cm_val4 <- 1
any(c(cm_val1, cm_val2, cm_val3, cm_val4) < 3)
i
i <- 1
subset <- subset(integrated, seurat_clusters == i)
### USER PARAMETERS
# read an integrated saved RDS file
sample_name <- "BL_N + BL_C"
integrated <- readRDS("F:/Maurits/EMC_SKlab_scRNA data/results/Pipe_SCTv2_corrected_13-06/integrated - new selection/BL_N + BL_C/BL_N + BL_C.rds")
# ## create condition markers for integrated data within each cluster between each condition
# ## DEV NOTE: this is not pairwise if more than 2 conditions are integrated at the same time
subset <- subset(integrated, seurat_clusters == i)
# ##  change cluster identity to original identity to find markers between conditions
Idents(subset) <- subset$orig.ident
## check if subset contains cells for at least 2 condtions/samples for comparison
### DEVNOTE: also need to check if a condition has ENOUGH cells for comparison?
if (length(names(table(subset$orig.ident))) == 1) {
print(paste0('In cluster ', i, ' only cells for condition/sample ',
names(table(subset$orig.ident)), ' were found, cannot create condition markers for this cluster.'))
next
}
## add amount of cells used for condition_markers comparison to df
condition_markers_df[nrow(condition_markers_df) + 1,] = c(i, table(subset$orig.ident)[1], table(subset$orig.ident)[2])
condition_markers_df <- data.frame(matrix(nrow = 0, ncol = length(condition_markers_columns)))
colnames(condition_markers_df) <- condition_markers_columns
## add amount of cells used for condition_markers comparison to df
condition_markers_df[nrow(condition_markers_df) + 1,] = c(i, table(subset$orig.ident)[1], table(subset$orig.ident)[2])
## conition markers
condition_markers_columns <- c('cluster_id',
paste0('n_cells_', names(table(integrated$orig.ident))[1]),
paste0('n_cells_', names(table(integrated$orig.ident))[2]))
condition_markers_df <- data.frame(matrix(nrow = 0, ncol = length(condition_markers_columns)))
colnames(condition_markers_df) <- condition_markers_columns
## add amount of cells used for condition_markers comparison to df
condition_markers_df[nrow(condition_markers_df) + 1,] = c(i, table(subset$orig.ident)[1], table(subset$orig.ident)[2])
condition_markers_df
## check more than 2 cells in subset ident (cluster) before comparison
if (any(c(subset$orig.ident)[1], subset$orig.ident)[2] < 3) {
message("For condition markers, skipping ident (cluster) ", i, " comparison because < 3 cells")
} else {
## create condition_markers for subset data for within each cluster to compare conditions
condition_markers <- FindMarkers(subset, assay = "SCT", recorrect_umi = FALSE, ident.1 = "BL_C", verbose = T, only.pos = FALSE)
# filters rows (genes) if they are >0.05 for both p_val and non-zero p_val with Bonferroni correction
condition_markers <- condition_markers[!(condition_markers$p_val_adj > 0.05 & condition_markers$nz_p_val_adj > 0.05),]
# pos_condition_markers <- condition_markers %>% filter(avg_log2FC > 0)
# neg_condition_markers <- condition_markers %>% filter(avg_log2FC < 0)
write.csv2(condition_markers, file = paste0("condition_markers/all_cluster", i, ".csv"))
print(paste('Cluster ID:', i, ' before condition_markers FGSEA call'))
# FGSEA_analysis(markers = condition_markers, working_directory = work_dir, marker_type = 'condition_markers', cluster = i)
message("wrote condition markers")
}
subset$orig.ident
subset$orig.ident)[1]
integrated$seurat_clusters
table(integrated$seurat_clusters)
subset$orig.ident
table(subset$orig.ident)
table(subset$orig.ident))[1]
table(subset$orig.ident)[1]
table(subset$orig.ident)[2]
c(table(subset$orig.ident)[1], table(subset$orig.ident)[2])
any(c(table(subset$orig.ident)[1], table(subset$orig.ident)[2]) < 3
)
source("F:/Maurits/EMC_SKlab_scRNA/Seurat/R/temp/DE & GSEA analysis - SCTv2-Neurolucida N+C newPostSelect.R")
